{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom tensorflow.keras.utils import to_categorical","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%matplotlib inline\nplt.style.use('ggplot')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train = pd.read_csv('/kaggle/input/quora-insincere-questions-classification/train.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from nltk.tokenize import RegexpTokenizer\nfrom  bs4 import BeautifulSoup\nregex = RegexpTokenizer(r'\\w+')\nimport nltk\n!nltk.download('stopwords')\nstopword = nltk.corpus.stopwords.words('english')\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def preprocess(text):\n    s = []\n    \n    lower = text.lower()\n    train_punkt = regex.tokenize(lower) \n    for j in train_punkt:\n        if j not in stopword:\n            s.append(j)\n          \n    if(len(s)==0):\n        return \"_nan_\"\n    return ' '.join(s)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_text = df_train['question_text'].map(preprocess)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nvocab_size = 10000\nembedding_dim = 16\nmax_length = 120\ntrunc_type='post'\noov_tok = \"<OOV>\"\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tokenizer = Tokenizer(num_words = vocab_size, oov_token=oov_tok)\ntokenizer.fit_on_texts(df_text)\nword_index = tokenizer.word_index\nsequences = tokenizer.texts_to_sequences(df_text)\npadded = pad_sequences(sequences,maxlen=max_length, truncating=trunc_type)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"word_counts = len(word_index)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.layers import Bidirectional, Dense, LSTM,Embedding, Dropout\nfrom tensorflow.keras.models import Sequential\ndef model():\n    model = Sequential([\n        Embedding(word_counts,100, input_length=max_length),\n        Bidirectional(LSTM(150, return_sequences=True)),\n        Dropout(0.2),\n        Bidirectional(LSTM(100)),\n        Dense(100, activation='relu'),\n        Dense(1, activation='sigmoid')\n    ])\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = model()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"labels = df_train['target'].values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.evaluate(padded, labels, batch_size=32,verbose=1, epochs=6)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#pytorch deplot to get higher speed\nword_counts = len(word_index)\nmax_length = 120\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from torch import optim, nn\nimport torchvision\nimport torch.nn.functional as F\nclass deep4layers(nn.Module):\n    def __init__(self ):\n        super(deep4layers, self).__init__()\n        self.embedding = nn.Embedding(word_counts, 100, max_length)\n        self.dense1 = nn.Linear(12000,100)\n        self.dense2 = nn.Linear(100,1)\n        self.drop = nn.Dropout(0.2)\n        self.bidirectional1 = nn.LSTM(100, 150, 1, bidirectional=True)\n        self.bidirectional2 = nn.LSTM(300, 100, 1, bidirectional=False)\n        self.flat = nn.Flatten()\n    def forward(self,x):\n        x = self.embedding(x)\n        x = self.bidirectional1(x)\n        x = self.drop(x[0])\n        x = self.bidirectional2(x)\n        x = self.flat(x[0])\n        x = F.relu(self.dense1(x))\n        x = F.sigmoid(self.dense2(x))\n        return x\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"deep4layers = deep4layers().cuda()\nloss_f = nn.BCELoss()\noptimer = optim.Adam(params=deep4layers.parameters(), lr=0.01)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class Dataset():\n    def __init__(self):\n        self.x = padded\n        self.y = labels\n        self.len = len(labels)\n    def __len__(self):\n        return len(labels)\n    def __getitem__(self, index):\n        return self.x[index,:], self.y[index]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from torch.utils.data import DataLoader\ndataloader = DataLoader(Dataset(), batch_size=32)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import torch\nuse_cuda = torch.cuda.is_available()\ndevice = torch.device('cuda:0' if use_cuda else 'cpu')\nprint(use_cuda)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tqdm import tqdm\nfrom torch.autograd import Variable\n\ndef train(epochs):\n    loss_acc = []\n    for i in range(epochs):\n        loss_e = 0\n        for x,y in tqdm(dataloader):\n            x = Variable(x).cuda(device) #move tensor to cuda\n            y = Variable(y).cuda(device) #move 130/3 faster\n                \n            ypred = deep4layers(x.long())\n            loss = loss_f(ypred,y.float())\n            optimer.zero_grad()\n            loss.backward()\n            optimer.step()\n            loss_e = loss_e + loss\n        loss_acc.append(loss_e)\n    return loss_acc\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"torch.cuda.reset_max_memory_allocated()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}